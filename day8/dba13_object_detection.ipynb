{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê°ì²´íƒì§€\n",
    "\n",
    "#### ê°œìš”\n",
    "- ë”¥ëŸ¬ë‹ì˜ CNN(ì™¸ RCNN ë“±)ì™€ ê°™ì€ ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ì„œ ë¬¼ì²´ë¥¼ ì¸ì‹í•˜ì—¬ í‘œì‹œí•˜ëŠ” ê¸°ìˆ \n",
    "- ìë™ì°¨ë²ˆí˜¸íŒ ë²ˆí˜¸ ì¸ì‹, í™”ì¬ê²½ë³´, êµí†µì‚¬ê³ ì¸ì§€, ì´ìƒí–‰ë™íŒŒì•… ë“±...\n",
    "- CCTVê³¼ ê°™ì´ ì ‘ëª©í•´ì„œ í™œìš©ë˜ëŠ” ê²½ìš°ê°€ ì•„ì£¼ ë§ìŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "- OpenCV - ìµœì´ˆ ì¸í…”ì—ì„œ ê°œë°œí•œ ì˜¤í”ˆì†ŒìŠ¤ ì‹¤ì‹œê°„ ì»´í“¨í„° ë¹„ì „ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "    - C/C++ì„ ëª©í‘œë¡œ ì œì‘. í¬ë¡œìŠ¤ í”Œë«í¼    \n",
    "    - íŒŒì´ì¬ì— OpenCVê°€ ì ìš©ë˜ë©´ì„œ í™œì„±í™”!\n",
    "    - ì¹´ë©”ë¼ ì¸ì‹ ì‚°ì—…ì—ì„œ ëŒ€ë¶€ë¶„ ì‚¬ìš©ë˜ê³  ìˆìŒ\n",
    "    - C/C++ì—ì„œ ê¸°ë³¸ ë™ì‘ì½”ë“œ 2~300ì¤„ì´ë©´ íŒŒì´ì¬ì—ì„  10ì¤„ì´ë‚´ë¡œ ê°™ì€ ì‘ì—…ì„ í•  ìˆ˜ ìˆìŒ\n",
    "\n",
    "- YOLO(PyTorch)\n",
    "    - Not You Only Live Once, You Only Look Once! \n",
    "    - ì†ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì‹¤ì‹œê°„ ê°ì²´ íƒì‹œ ì‹œìŠ¤í…œ\n",
    "    - 2015ë…„ì— ì¶œì‹œí›„ í˜„ì¬ 2024ë…„ í˜„ì¬ v8.0 \n",
    "    - OpenCVë§Œ ê°€ì§€ê³  ì‘ì—…í•˜ë˜ ê±¸, YOLOë¡œ ë„˜ì–´ê°€ëŠ” ì¶”ì„¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from opencv-python) (1.26.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Window, Mac ì°¨ì´ê°€ ì—†ìŒ\n",
    "## Raspbarry PiëŠ” ìµœì„ ë²„ì „ì—ì„œ ì‚¬ìš©ë²•ì´ ë³€ê²½ë˜ì—ˆìŒ.\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ì´ë¯¸ì§€ ë¡œë“œ\n",
    "## ì‚¬ë§‰ì—¬ìš° == Fennec Fox\n",
    "img = cv2.imread('./fennec_fox.png')\n",
    "\n",
    "cv2.imshow('Fox', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## í˜„ì¬ ì›¹ìº ì´ ë™ì‘ ì•ˆí•¨\n",
    "video_path = './Mumbai_traffic.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path) # 0~ìˆ«ìëŠ” ì¹´ë©”ë¼ë²ˆí˜¸\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "while (cap.isOpened()):  ## True => (cap.isOpened())\n",
    "    ret, img = cap.read() # ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì„ ìº¡ì³ ret(ê²°ê³¼ì •ë³´ê°ì²´), img(ì‹¤ì‹œê°„ì´ë¯¸ì§€)\n",
    "    if ret == True:\n",
    "        cv2.imshow('youtube mpeg', img) ## ë‚´ë¶€ì ìœ¼ë¡œ PyQtë¡œ ìƒì„±ë˜ëŠ” GUIì°½\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'): # í‚¤ë³´ë“œ që¥¼ í´ë¦­í•˜ë©´\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release() # ìì› í•´ì œ\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ì´ë¯¸ì§€ ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./fennec_fox.png')\n",
    "\n",
    "cv2.imshow('Original', img) ## ì¼ë°˜ ì´ë¯¸ì§€\n",
    "# cv2.waitKey(0) \n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "height, width = img.shape[0], img.shape[1]\n",
    "## ì •ìˆ˜ì…ë ¥ width/2 => float ë¬¸ì œ\n",
    "half_img = cv2.resize(gray, (int(width/2), int(height/2)))\n",
    "# cv2.imshow('Gray', gray) ## í‘ë°± ë³€í™˜\n",
    "cv2.imshow('half', half_img)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = './Mumbai_traffic.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path) # 0~ìˆ«ìëŠ” ì¹´ë©”ë¼ë²ˆí˜¸\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "while (cap.isOpened()):   \n",
    "    ret, img = cap.read() # ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì„ ìº¡ì³ ret(ê²°ê³¼ì •ë³´ê°ì²´) ë³´í†µ ì‚¬ìš©í•˜ì§€ ì•Šì•„ì„œ _ë¡œ ë³€ê²½, img(ì‹¤ì‹œê°„ì´ë¯¸ì§€)\n",
    "    if ret == True:\n",
    "        # cv2.imshow('youtube mpeg', img) ## ë‚´ë¶€ì ìœ¼ë¡œ PyQtë¡œ ìƒì„±ë˜ëŠ” GUIì°½\n",
    "        height, width = img.shape[0], img.shape[1]\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  ## ì»¬ëŸ¬ -> í‘ë°±ìœ¼ë¡œ\n",
    "        half = cv2.resize(gray, (int(width/2), int(height/2))) ## ì‚¬ì´ì¦ˆë¥¼ ë°˜ìœ¼ë¡œ ì¶•ì†Œ\n",
    "        cv2.imshow('youtube gray', half)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'): # í‚¤ë³´ë“œ që¥¼ í´ë¦­í•˜ë©´\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release() # ìì› í•´ì œ\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- í¬í† ìƒµë“±ì˜ ì´ë¯¸ì§€, í”„ë¦¬ë¯¸ì–´ë“±ì˜ ë™ì˜ìƒ ì²˜ë¦¬í•˜ëŠ” í”„ë¡œê·¸ë¨ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê±°ì˜ ëŒ€ë¶€ë¶„ì˜ ê¸°ëŠ¥ì´ OpenCVì— í¬í•¨ë˜ì–´ ìˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = './mbc_news.mp4'\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(video_path) # 0~ìˆ«ìëŠ” ì¹´ë©”ë¼ë²ˆí˜¸\n",
    "\n",
    "while (cap.isOpened()):    \n",
    "    ret, img = cap.read() # ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì„ ìº¡ì³ ret(ê²°ê³¼ì •ë³´ê°ì²´) ë³´í†µ ì‚¬ìš©í•˜ì§€ ì•Šì•„ì„œ _ë¡œ ë³€ê²½, img(ì‹¤ì‹œê°„ì´ë¯¸ì§€)\n",
    "    if ret == True:\n",
    "        height, width = img.shape[0], img.shape[1]\n",
    "\n",
    "        half = cv2.resize(img, (int(width/2), int(height/2)))\n",
    "\n",
    "        # ì–¼êµ´ì¸ì‹\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            half,\n",
    "            scaleFactor=2.0,\n",
    "            minNeighbors=5,\n",
    "            minSize=(10,10)\n",
    "        )\n",
    "        ## ì°¾ì€ ì–¼êµ´ ìœ„ì¹˜ í‘œì‹œ\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(half,(x,y),(x+w,y+h),(0,255,255), 2)\n",
    "            roi_color = half[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.imshow('youtube mpeg', half) ## ë‚´ë¶€ì ìœ¼ë¡œ PyQtë¡œ ìƒì„±ë˜ëŠ” GUIì°½\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'): # í‚¤ë³´ë“œ që¥¼ í´ë¦­í•˜ë©´\n",
    "            break\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release() # ìì› í•´ì œ\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YOLO\n",
    "- You Only Look Once - CNNì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ë¬¼ì²´ ê°ì§€ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "- https://www.ultralytics.com/ko\n",
    "- https://github.com/ultralytics/ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (8.2.76)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (1.26.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (3.9.1.post1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (1.14.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (2.4.0+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (0.19.0+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (2.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
      "Requirement already satisfied: filelock in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.2.0)\n",
      "Requirement already satisfied: colorama in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# YOLO ì„¤ì¹˜\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "Ultralytics YOLOv8.2.76 ğŸš€ Python-3.11.5 torch-2.4.0+cu121 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 c:\\Sources\\iot-bigdata-2024\\day8\\bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 28.5ms\n",
      "Speed: 3.5ms preprocess, 28.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mC:\\Sources\\iot-bigdata-2024\\runs\\detect\\predict2\u001b[0m\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/6.25M [00:00<?, ?B/s]\n",
      "  2%|â–         | 128k/6.25M [00:00<00:05, 1.07MB/s]\n",
      "  8%|â–Š         | 512k/6.25M [00:00<00:02, 2.13MB/s]\n",
      " 12%|â–ˆâ–        | 768k/6.25M [00:00<00:02, 2.29MB/s]\n",
      " 20%|â–ˆâ–ˆ        | 1.25M/6.25M [00:00<00:02, 2.52MB/s]\n",
      " 28%|â–ˆâ–ˆâ–Š       | 1.75M/6.25M [00:00<00:01, 3.16MB/s]\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.62M/6.25M [00:00<00:00, 4.74MB/s]\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3.50M/6.25M [00:00<00:00, 5.07MB/s]\n",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 4.12M/6.25M [00:01<00:00, 5.34MB/s]\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5.25M/6.25M [00:01<00:00, 7.01MB/s]\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 6.00M/6.25M [00:01<00:00, 7.19MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:01<00:00, 5.11MB/s]\n"
     ]
    }
   ],
   "source": [
    "## ì½˜ì†”ì°½ì—ì„œ í…ŒìŠ¤íŠ¸í•˜ëŠ” ë°©ë²•, íŠ¸ë ˆì´ë‹í•œ ì´ë¯¸ì§€ì²˜ë¦¬ ëª¨ë¸\n",
    "!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/bus.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Sources\\iot-bigdata-2024\\day8\\20190417_194709.jpg: 384x640 1 bottle, 1 cup, 1 bowl, 1 tv, 1 mouse, 31.3ms\n",
      "Speed: 5.0ms preprocess, 31.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# ì´ë¯¸ì§€ì™€ openCV ë¬¼ì²´ê°ì§€\n",
    "model = YOLO(model='./yolov8n.pt')\n",
    "\n",
    "result = model('./20190417_194709.jpg')\n",
    "plots = result[0].plot()\n",
    "height, width = plots.shape[0], plots.shape[1]\n",
    "last = cv2.resize(plots, (800, 450))\n",
    "cv2.imshow('yolo', last)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ì‹¤ì‹œê°„ ê°€ëŠ¥, ë™ì˜ìƒë„ ê°€ëŠ¥\n",
    "classNames = [\n",
    "                \"person\", \"bicycle\", \"car\", \"motorbike\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "                \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "                \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "                \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "                \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "                \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "                \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "                \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "                \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "                \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Mumbai_traffic.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mVideoCapture(video_path) \u001b[38;5;66;03m# ìˆ«ìëŠ” CCTV,ì›¹ìº  ë“± ì‹¤ì‹œê°„ ì˜ìƒ\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (cap\u001b[38;5;241m.\u001b[39misOpened()):\n\u001b[0;32m      6\u001b[0m     ret, img \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "video_path = './Mumbai_traffic.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path) # ìˆ«ìëŠ” CCTV,ì›¹ìº  ë“± ì‹¤ì‹œê°„ ì˜ìƒ\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    if ret == True:\n",
    "        height, width = img.shape[0], img.shape[1]\n",
    "        half = cv2.resize(img, (int(width/2), int(height/2)))\n",
    "        # YOLOë¡œ ë¬¼ì²´ê²€ì¶œ ì‹œì‘\n",
    "        results = model(half, stream=True)\n",
    "\n",
    "        ## ê²°ê³¼í‘œì‹œ like OpenCV ì–¼êµ´ê²€ì¶œ\n",
    "        for result in results:\n",
    "            ## ì•„ë˜ì˜ ì…€ì˜ ê²°ê³¼ê°€ ê°„ë‹¨\n",
    "            boxes = result.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                cv2.rectangle(half, (x1,y1), (x2,y2), (0,255,255), 2) # ê²€ì¶œëœ ë¬¼ì²´ ë°•ìŠ¤ê·¸ë¦¬ê¸°\n",
    "\n",
    "                ## ì •í™•ë„ê³„ì‚°, Class name\n",
    "                accuracy = (box.conf[0]/100)*100\n",
    "                index = int(box.cls[0])\n",
    "                # print(f'ClassName : {classNames[index]} / Accuracy : {accuracy:.2f}') # ì½˜ì†”í”„ë¦°íŠ¸ëŠ” ìƒëµ\n",
    "                title = f'{classNames[index]}, {accuracy:.2f}'\n",
    "                ## ë°•ìŠ¤ìœ„ì— ì¢…ë¥˜ì™€ ì •í™•ë„ì¶œë ¥\n",
    "                org = [x1, y1] \n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                fontScale = 0.6\n",
    "                color = (0,255,255)\n",
    "                thickness = 2\n",
    "\n",
    "                cv2.putText(half, title, org, font, fontScale, color, thickness)\n",
    "\n",
    "        cv2.imshow('YOLOv8', half)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Mumbai_traffic.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mVideoCapture(video_path) \u001b[38;5;66;03m# ìˆ«ìëŠ” CCTV,ì›¹ìº  ë“± ì‹¤ì‹œê°„ ì˜ìƒ\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (cap\u001b[38;5;241m.\u001b[39misOpened()):\n\u001b[0;32m      6\u001b[0m     ret, img \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "video_path = './Mumbai_traffic.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path) # ìˆ«ìëŠ” CCTV,ì›¹ìº  ë“± ì‹¤ì‹œê°„ ì˜ìƒ\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    if ret == True:\n",
    "        height, width = img.shape[0], img.shape[1]\n",
    "        half = cv2.resize(img, (int(width/2), int(height/2)))\n",
    "        results = model(half, stream=True)\n",
    "\n",
    "        for result in results:\n",
    "            last = result.plot()\n",
    "\n",
    "        cv2.imshow('YOLOv8', last)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m height, width \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     10\u001b[0m half \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (\u001b[38;5;28mint\u001b[39m(width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m), \u001b[38;5;28mint\u001b[39m(height\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m---> 11\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m(half, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m     14\u001b[0m     last \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mplot()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "video_path = './Mumbai_traffic.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "out = cv2.VideoWriter('./Mumbai_traffic_result.mp4', fourcc=1446269005, fps=30, frameSize=(640,360))\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    if ret == True:\n",
    "        height, width = img.shape[0], img.shape[1]\n",
    "        half = cv2.resize(img, (int(width/2), int(height/2)))\n",
    "        results = model(half, stream=True)\n",
    "\n",
    "        for result in results:\n",
    "            last = result.plot()\n",
    "\n",
    "        cv2.imshow('YOLOv8', last)\n",
    "        out.write(last)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
